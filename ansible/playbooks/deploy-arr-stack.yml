---
# Deploy *arr stack services using Nomad Pack
#
# This playbook deploys the media automation stack:
#   - Radarr (movie management)
#   - Sonarr (TV series management)
#   - Lidarr (music management)
#   - Prowlarr (indexer management)
#   - Seerr (request management) - default
#   - Overseerr (request management) - alternative to Seerr
#   - Tautulli (Plex monitoring)
#   - SABnzbd (Usenet download client)
#   - seerr-reverse-proxy (HTTPS proxy for Seerr) - optional
#   - overseerr-reverse-proxy (HTTPS proxy for Overseerr) - optional
#
# Usage:
#   Deploy all services:
#     ansible-playbook -i inventory.ini playbooks/deploy-arr-stack.yml
#
#   Deploy specific services:
#     ansible-playbook -i inventory.ini playbooks/deploy-arr-stack.yml -e "arr_services=['radarr','sonarr','sabnzbd']"
#
#   Use Overseerr instead of Seerr:
#     ansible-playbook -i inventory.ini playbooks/deploy-arr-stack.yml -e "arr_services=['radarr','sonarr','lidarr','prowlarr','overseerr','tautulli','sabnzbd']"
#
#   Deploy with HTTPS reverse proxy (requires proxy_dns_name):
#     ansible-playbook -i inventory.ini playbooks/deploy-arr-stack.yml -e "arr_services=['radarr','sonarr','lidarr','prowlarr','seerr','seerr-reverse-proxy','tautulli','sabnzbd']" -e proxy_dns_name=requests.example.com
#
#   Without backups:
#     ansible-playbook -i inventory.ini playbooks/deploy-arr-stack.yml -e arr_enable_backup=false
#
#   Restore from backup:
#     ansible-playbook -i inventory.ini playbooks/deploy-arr-stack.yml -e restore_from_backup=true
#
#   Restore specific services from backup:
#     ansible-playbook -i inventory.ini playbooks/deploy-arr-stack.yml -e "arr_services=['radarr']" -e restore_from_backup=true
#
#   Restore from specific date:
#     ansible-playbook -i inventory.ini playbooks/deploy-arr-stack.yml -e restore_from_backup=true -e backup_date=2025-01-15

- name: Deploy *arr Stack
  hosts: controller
  gather_facts: true
  vars:
    # Default list of services to deploy (seerr is default, use overseerr as alternative)
    # Reverse proxies are optional and require proxy_dns_name to be set
    arr_services:
      - radarr
      - sonarr
      - lidarr
      - prowlarr
      - seerr
      - tautulli
      - sabnzbd
    # Valid service names
    valid_services:
      - radarr
      - sonarr
      - lidarr
      - prowlarr
      - seerr
      - overseerr
      - tautulli
      - sabnzbd
      - seerr-reverse-proxy
      - overseerr-reverse-proxy
    # Services that don't need host volumes (reverse proxies use the parent service's volume for co-location)
    proxy_services:
      - seerr-reverse-proxy
      - overseerr-reverse-proxy
    # Pack variables
    arr_enable_backup: true
    arr_enable_update: true
    # Restore from backup (default: false)
    restore_from_backup: false
  tasks:
    - name: Validate arr_services
      ansible.builtin.assert:
        that:
          - arr_services | length > 0
          - arr_services | difference(valid_services) | length == 0
        fail_msg: "arr_services must contain valid service names: {{ valid_services | join(', ') }}"
        success_msg: "Will deploy services: {{ arr_services | join(', ') }}"

    - name: Check seerr and overseerr exclusivity
      ansible.builtin.assert:
        that:
          - not ('seerr' in arr_services and 'overseerr' in arr_services)
        fail_msg: "Cannot deploy both seerr and overseerr simultaneously. They use the same port (5055). Choose one or the other."
        success_msg: "Request manager: {{ 'seerr' if 'seerr' in arr_services else ('overseerr' if 'overseerr' in arr_services else 'none') }}"

    - name: Check reverse proxy exclusivity
      ansible.builtin.assert:
        that:
          - not ('seerr-reverse-proxy' in arr_services and 'overseerr-reverse-proxy' in arr_services)
        fail_msg: "Cannot deploy both seerr-reverse-proxy and overseerr-reverse-proxy simultaneously. They use the same ports (80/443). Choose one or the other."
        success_msg: "Reverse proxy: {{ 'seerr-reverse-proxy' if 'seerr-reverse-proxy' in arr_services else ('overseerr-reverse-proxy' if 'overseerr-reverse-proxy' in arr_services else 'none') }}"

    - name: Check reverse proxy matches request manager
      ansible.builtin.assert:
        that:
          - not ('seerr-reverse-proxy' in arr_services and 'overseerr' in arr_services)
          - not ('overseerr-reverse-proxy' in arr_services and 'seerr' in arr_services)
        fail_msg: "Reverse proxy must match request manager. Use seerr-reverse-proxy with seerr, or overseerr-reverse-proxy with overseerr."
        success_msg: "Reverse proxy configuration is valid"
      when: "'seerr-reverse-proxy' in arr_services or 'overseerr-reverse-proxy' in arr_services"

    - name: Check proxy_dns_name is set when deploying reverse proxy
      ansible.builtin.assert:
        that:
          - proxy_dns_name is defined
          - proxy_dns_name | length > 0
        fail_msg: "proxy_dns_name must be set when deploying a reverse proxy (e.g., -e proxy_dns_name=requests.example.com)"
        success_msg: "Reverse proxy DNS: {{ proxy_dns_name }}"
      when: "'seerr-reverse-proxy' in arr_services or 'overseerr-reverse-proxy' in arr_services"

    # Check Nomad Pack is installed
    - name: Check if Nomad Pack is installed
      ansible.builtin.command:
        cmd: nomad-pack version
      register: nomad_pack_check
      changed_when: false
      failed_when: false

    - name: Install Nomad Pack if not present
      when: nomad_pack_check.rc != 0
      block:
        - name: Tap HashiCorp repository
          community.general.homebrew_tap:
            name: hashicorp/tap
            state: present

        - name: Install Nomad Pack via Homebrew
          community.general.homebrew:
            name: hashicorp/tap/nomad-pack
            state: latest

    # Ensure registry is configured
    - name: Check if Nomad Pack registry exists
      ansible.builtin.command:
        cmd: nomad-pack registry list
      environment:
        NOMAD_ADDR: "{{ nomad_addr }}"
      register: registry_list
      changed_when: false
      failed_when: false

    - name: Add Nomad Pack registry
      ansible.builtin.command:
        cmd: nomad-pack registry add {{ nomad_pack_registry_name }} {{ nomad_pack_registry_url }}
      environment:
        NOMAD_ADDR: "{{ nomad_addr }}"
      when: nomad_pack_registry_name not in registry_list.stdout
      register: registry_add
      changed_when: "'added' in registry_add.stdout"

    # Create host volumes for each service (excluding reverse proxies which use parent service's volume)
    - name: Create host volumes for *arr services
      ansible.builtin.shell: |
        nomad volume create - <<'EOF'
        name      = "{{ item }}-config"
        type      = "host"
        plugin_id = "mkdir"
        capability {
          access_mode     = "single-node-multi-writer"
          attachment_mode = "file-system"
        }
        parameters {
          mode = "0755"
          uid  = "{{ user_uid }}"
          gid  = "{{ group_gid }}"
        }
        EOF
      environment:
        NOMAD_ADDR: "{{ nomad_addr }}"
      loop: "{{ arr_services | difference(proxy_services) }}"
      register: host_volumes
      changed_when: "'Created' in host_volumes.stdout"
      failed_when: false

    - name: Display host volume results
      ansible.builtin.debug:
        msg: "{{ item.item }}-config: {{ 'created' if 'Created' in item.stdout else 'already exists or failed' }}"
      loop: "{{ host_volumes.results }}"
      loop_control:
        label: "{{ item.item }}"
      when: host_volumes.results | length > 0

    #
    # RESTORE FROM BACKUP WORKFLOW
    # If restore_from_backup=true, we:
    #   1. Deploy with enable_restore=true (creates restore job)
    #   2. Dispatch the restore job for each service
    #   3. Wait for completion
    #   4. Redeploy with enable_restore=false (removes restore job, starts service)
    #
    - name: Restore from backup workflow
      when: restore_from_backup | bool
      block:
        - name: Display restore workflow start
          ansible.builtin.debug:
            msg: "Starting restore workflow for {{ arr_services | join(', ') }}..."

        - name: Deploy restore jobs for all services
          ansible.builtin.command:
            cmd: >-
              nomad-pack run --registry={{ nomad_pack_registry_name }}
              --var enable_backup=false
              --var enable_update=false
              --var enable_restore=true
              {{ item }}
          environment:
            NOMAD_ADDR: "{{ nomad_addr }}"
          loop: "{{ arr_services | difference(proxy_services) }}"
          register: restore_deploys
          changed_when: "'deployed' in restore_deploys.stdout or 'Plan' in restore_deploys.stdout"

        - name: Wait for restore jobs to be registered
          ansible.builtin.pause:
            seconds: 5

        - name: Dispatch restore jobs
          ansible.builtin.command:
            cmd: >-
              nomad job dispatch
              {{ '-meta backup_date=' + backup_date if backup_date is defined else '' }}
              {{ item }}-restore
          environment:
            NOMAD_ADDR: "{{ nomad_addr }}"
          loop: "{{ arr_services | difference(proxy_services) }}"
          register: dispatch_results
          changed_when: true

        - name: Extract dispatch job IDs
          ansible.builtin.set_fact:
            dispatch_jobs: "{{ dispatch_jobs | default([]) + [{'service': item.item, 'job_id': item.stdout | regex_search('Dispatched Job ID = (.+)', '\\1') | first}] }}"
          loop: "{{ dispatch_results.results }}"
          loop_control:
            label: "{{ item.item }}"

        - name: Display dispatched restore jobs
          ansible.builtin.debug:
            msg: "{{ item.service }}-restore dispatched: {{ item.job_id }}"
          loop: "{{ dispatch_jobs }}"
          loop_control:
            label: "{{ item.service }}"

        - name: Wait for all restore jobs to complete
          ansible.builtin.command:
            cmd: nomad job status {{ item.job_id }}
          environment:
            NOMAD_ADDR: "{{ nomad_addr }}"
          loop: "{{ dispatch_jobs }}"
          loop_control:
            label: "{{ item.service }}"
          register: job_statuses
          until: "'dead' in job_statuses.stdout or 'complete' in job_statuses.stdout"
          retries: 60
          delay: 5
          changed_when: false

        - name: Get restore job logs
          ansible.builtin.command:
            cmd: nomad alloc logs -job {{ item.job_id }}
          environment:
            NOMAD_ADDR: "{{ nomad_addr }}"
          loop: "{{ dispatch_jobs }}"
          loop_control:
            label: "{{ item.service }}"
          register: restore_logs
          changed_when: false

        - name: Display restore results
          ansible.builtin.debug:
            msg: |
              {{ item.item.service }} restore:
              {{ 'SUCCESS' if 'Restore complete!' in item.stdout else 'FAILED - check logs' }}
          loop: "{{ restore_logs.results }}"
          loop_control:
            label: "{{ item.item.service }}"

        - name: Check for any failed restores
          ansible.builtin.fail:
            msg: "One or more restore jobs failed. Check logs above."
          when: restore_logs.results | selectattr('stdout', 'not search', 'Restore complete!') | list | length > 0

        - name: Display restore success
          ansible.builtin.debug:
            msg: "All restores completed successfully. Now deploying services..."

    #
    # NORMAL DEPLOYMENT
    # Deploy all services (with restore jobs removed if they were created)
    #
    - name: Set pack variables
      ansible.builtin.set_fact:
        pack_vars: >-
          --var enable_backup={{ arr_enable_backup | lower }}
          --var enable_update={{ arr_enable_update | lower }}
          --var enable_restore=false

    - name: Deploy *arr services with Nomad Pack (excluding proxies)
      ansible.builtin.command:
        cmd: nomad-pack run --registry={{ nomad_pack_registry_name }} {{ pack_vars }} {{ item }}
      environment:
        NOMAD_ADDR: "{{ nomad_addr }}"
      loop: "{{ arr_services | difference(proxy_services) }}"
      register: pack_results
      changed_when: "'deployed' in pack_results.stdout or 'Plan' in pack_results.stdout"

    - name: Deploy reverse proxy with Nomad Pack
      ansible.builtin.command:
        cmd: >-
          nomad-pack run --registry={{ nomad_pack_registry_name }}
          --var dns_name={{ proxy_dns_name }}
          {{ item }}
      environment:
        NOMAD_ADDR: "{{ nomad_addr }}"
      loop: "{{ arr_services | intersect(proxy_services) }}"
      register: proxy_results
      changed_when: "'deployed' in proxy_results.stdout or 'Plan' in proxy_results.stdout"
      when: arr_services | intersect(proxy_services) | length > 0

    - name: Display deployment results
      ansible.builtin.debug:
        msg: "{{ item.item }}: {{ 'deployed' if item.rc == 0 else 'failed' }}"
      loop: "{{ pack_results.results }}"
      loop_control:
        label: "{{ item.item }}"

    - name: Display proxy deployment results
      ansible.builtin.debug:
        msg: "{{ item.item }}: {{ 'deployed' if item.rc == 0 else 'failed' }}"
      loop: "{{ proxy_results.results | default([]) }}"
      loop_control:
        label: "{{ item.item }}"
      when: proxy_results.results is defined and proxy_results.results | length > 0

    # Verify all jobs are running
    - name: Wait for services to start
      ansible.builtin.command:
        cmd: nomad job status {{ item }}
      environment:
        NOMAD_ADDR: "{{ nomad_addr }}"
      loop: "{{ arr_services }}"
      register: job_status
      until: "'running' in job_status.stdout"
      retries: 30
      delay: 5
      changed_when: false

    - name: Display service URLs
      ansible.builtin.debug:
        msg: |
          *arr stack deployed successfully!
          {% if restore_from_backup | bool %}
          Configuration was restored from backup{{ ' (' + backup_date + ')' if backup_date is defined else ' (latest)' }}.
          {% endif %}

          Service URLs:
          {% if 'radarr' in arr_services %}
            - Radarr:    http://192.168.0.10:7878
          {% endif %}
          {% if 'sonarr' in arr_services %}
            - Sonarr:    http://192.168.0.10:8989
          {% endif %}
          {% if 'lidarr' in arr_services %}
            - Lidarr:    http://192.168.0.10:8686
          {% endif %}
          {% if 'prowlarr' in arr_services %}
            - Prowlarr:  http://192.168.0.10:9696
          {% endif %}
          {% if 'seerr' in arr_services %}
            - Seerr:     http://192.168.0.10:5055
          {% endif %}
          {% if 'seerr-reverse-proxy' in arr_services %}
            - Seerr (HTTPS): https://{{ proxy_dns_name }}
          {% endif %}
          {% if 'overseerr' in arr_services %}
            - Overseerr: http://192.168.0.10:5055
          {% endif %}
          {% if 'overseerr-reverse-proxy' in arr_services %}
            - Overseerr (HTTPS): https://{{ proxy_dns_name }}
          {% endif %}
          {% if 'tautulli' in arr_services %}
            - Tautulli:  http://192.168.0.10:8181
          {% endif %}
          {% if 'sabnzbd' in arr_services %}
            - SABnzbd:   http://192.168.0.10:8080
          {% endif %}

          Next steps:
            1. Configure Prowlarr with your indexers
            2. Add Prowlarr to Radarr/Sonarr/Lidarr (Settings â†’ Indexers)
            3. Configure download clients in each *arr app
            4. Connect {{ 'Seerr' if 'seerr' in arr_services else 'Overseerr' }} to your media server and Radarr/Sonarr
            5. Connect Tautulli to Plex
